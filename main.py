import os
import requests
from collections import Counter
from bs4 import BeautifulSoup
import re

# 1. P캐rbauda un izveido failu ievadei
filename = "ievade.txt"
if not os.path.exists(filename):
    with open(filename, "w", encoding="utf-8") as f:
        f.write("Ievadi savu tekstu 코eit...")

print(f"\nL콞dzu, ievadi tekstu fail캐: {filename}")
input("Kad esi gatavs, nospied Enter...")

# 2. Nolasa failu un apstr캐d캐 v캐rdus
with open(filename, "r", encoding="utf-8") as f:
    text = f.read().lower()

words = re.findall(r'\b[a-z캐캜캡캮캶컁컆켽코콞쬪-]+\b', text.lower())

#noteikt lemma - v캐rda pamatforma
def get_lemma(word):
    url = f"https://tezaurs.lv/{word}"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            return word
    except requests.RequestException:
        return word

    soup = BeautifulSoup(response.text, "html.parser")

    # M캡캮ina atrast bloku ar tekstu "forma 코컁irkl캶"
    for div in soup.find_all("div", class_="listItem"):
        if "forma 코컁irkl캶" in div.get_text().lower():
            link = div.find("a", href=True)
            if link:
                lemma = link.get_text(strip=True).lower()
                return lemma
            
    return word

lemmas = [get_lemma(word) for word in words]
lemma_counts = Counter(lemmas)
repeated_lemmas = [lemma for lemma, count in lemma_counts.items() if count > 1 and lemma]

print("\n游대 Atk캐rtojo코ie v캐rdi tekst캐:")
print(", ".join(repeated_lemmas) if repeated_lemmas else "Nav atk캐rtojo코u v캐rdu.")

# V캐rdi, kurus v캡lamies izsl캡gt no rezult캐ta
exclude_words = {"apvidv캐rds", "쬬rgonisms", "loc캶코ana", "fraz캡ma", "idioma", "kolok캐cija", "sarunvaloda", "taksons", "piem캡ri", "frazeolo캮isms", "tulkojumi", "v캐rdkoptermins"}

def extract_single_word_synonyms(raw_list):
    cleaned = []
    for item in raw_list:
        item = re.sub(r'\d+', '', item)
        item = item.strip().lower()
        if item in exclude_words:
            continue
        if item and (' ' not in item) and re.match(r'^[a-z캐캜캡캮캶컁컆켽코콞-]+$', item):
            cleaned.append(item)
    return sorted(set(cleaned))

# Lok캐ls v캐rd코컁iru v캐rdn캶ca popul캐r캐kajiem v캐rdiem
pos_lookup = {
    "un": "saiklis",
    "vai": "saiklis",
    "bet": "saiklis",
    "par": "priev캐rds",
    "ar": "priev캐rds",
    "uz": "priev캐rds",
    "es": "vietniekv캐rds",
    "tu": "vietniekv캐rds",
    "vi켽코": "vietniekv캐rds",
    "m캡s": "vietniekv캐rds",
    "j콞s": "vietniekv캐rds",
    "vi켽i": "vietniekv캐rds",
    "tas": "vietniekv캐rds",
    "코o": "vietniekv캐rds",
    "pie": "priev캐rds",
    "dom캐t": "darb캶bas v캐rds",
    "emocijas": "lietv캐rds",
    "suns": "lietv캐rds",
    "r캶ts": "lietv캐rds",
    # papildini p캡c vajadz캶bas
}

# Funkcija v캐rd코컁iras ieg콞코anai
def get_word_pos(word):
    # 1. P캐rbauda lok캐lo v캐rdn캶cu
    if word in pos_lookup:
        return pos_lookup[word]

    # 2. Scrapo no Tezaurs.lv
    url = f"https://tezaurs.lv/{word}"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            return None
    except requests.RequestException:
        return None

    soup = BeautifulSoup(response.text, "html.parser")

    # Mekl캡 elementus, kur parasti ir v캐rd코컁ira
    # Piem캡ram, m캡캮in캐m atrast <p> vai <span> ar atbilsto코u klasi
    pos_tags = soup.find_all(["span", "p", "div"], class_=re.compile(r"(part-of-speech|pos|grammatical)"))
    for tag in pos_tags:
        text = tag.get_text(strip=True).lower()
        if text:
            return text

    # Ja nav atrasts ar speci캐lu klasi, mekl캡 tekst캐 v캐rd코컁iras v캐rdus
    text = soup.get_text(separator="\n").lower()
    pos_words = ["lietv캐rds", "darb캶bas v캐rds", "캶pa코캶bas v캐rds", "skait컆a v캐rds", "priev캐rds", "saiklis", "pied캡klis", "da컆a", "apst캐k컆a v캐rds", "vietniekv캐rds"]
    for pw in pos_words:
        if pw in text:
            return pw

    return None

# Funkcija sinon캶mu ieg콞코anai
def get_hidden_synonyms(word):
    url = f"https://tezaurs.lv/{word}"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            return []
    except requests.RequestException:
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    synonyms = set()

    for block in soup.find_all(["div", "ul"], class_="synonyms"):
        for item in block.find_all(["li", "span"]):
            text = item.get_text(strip=True)
            if text:
                synonyms.add(text)

    for hidden in soup.find_all(style=True):
        style = hidden['style'].replace(" ", "").lower()
        if 'display:none' in style:
            for item in hidden.find_all(["li", "span"]):
                text = item.get_text(strip=True)
                if text:
                    synonyms.add(text)

    return list(synonyms)

# 4. Ieg콞st v캐rdus ar v캐rd코컁iru un sinon캶mus, izvada tikai tos v캐rdus, kam ir atrasti sinon캶mi
print("\n==== REZULTTI ====")
for lemma in repeated_lemmas:
    pos = get_word_pos(lemma)
    if pos == "saiklis":
        continue
    synonyms = extract_single_word_synonyms(get_hidden_synonyms(lemma))
    if synonyms:
        print(f"\nSinon캶mi v캐rdam '{lemma}' ({pos if pos else 'v캐rd코컁ira nav atrasta'}):")
        print(", ".join(synonyms))
